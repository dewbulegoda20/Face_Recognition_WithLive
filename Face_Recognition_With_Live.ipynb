{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf075ef-8439-40e8-8d77-00ee7cb43b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in c:\\users\\user\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (10.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4839a6b6-7d28-4526-8cd3-9284b79f5d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1726433-00d2-43b8-b8c6-a26ad37e9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cbc0449-3734-4e7d-8ff4-536ca0ad411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c3a1b0-2af8-445a-b06c-7e68e09fb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load known faces\n",
    "Bill_image = face_recognition.load_image_file(\"photos/Bill.jpg\")\n",
    "Bill_encoding = face_recognition.face_encodings(Bill_image)[0]\n",
    "\n",
    "Elon_image = face_recognition.load_image_file(\"photos/Elon.jpg\")\n",
    "Elon_encoding = face_recognition.face_encodings(Elon_image)[0]\n",
    "\n",
    "Mark_image = face_recognition.load_image_file(\"photos/Mark.jpg\")\n",
    "Mark_encoding = face_recognition.face_encodings(Mark_image)[0]\n",
    "\n",
    "Steve_image = face_recognition.load_image_file(\"photos/Steve.jpg\")\n",
    "Steve_encoding = face_recognition.face_encodings(Steve_image)[0]\n",
    "\n",
    "Dewmini_image = face_recognition.load_image_file(\"photos/Dewmini.jpg\")\n",
    "Dewmini_encoding = face_recognition.face_encodings(Dewmini_image)[0]\n",
    "\n",
    "known_face_encoding = [Bill_encoding, Elon_encoding, Mark_encoding, Steve_encoding, Dewmini_encoding]\n",
    "known_faces_names = [\"Bill\", \"Elon\", \"Mark\", \"Steve\", \"Dewmini\"]\n",
    "students = known_faces_names.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f123c1c-a556-4946-8c33-5746cd3b2313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "- Move your head slightly or blink naturally\n",
      "- Stay still for too long = not live\n",
      "- Green box = Live person, Red = Static/Fake\n",
      "- Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "# Simple liveness detection variables\n",
    "previous_frame = None\n",
    "liveness_threshold = 1000  # Minimum motion required\n",
    "liveness_verified = {}\n",
    "motion_frames_required = 30  # Frames of motion needed\n",
    "recognition_delay = 60  # Frames to wait before allowing attendance\n",
    "\n",
    "# CSV setup\n",
    "now = datetime.now()\n",
    "current_date = now.strftime(\"%Y-%m-%d\")\n",
    "f = open(current_date + '.csv', 'w+', newline='')\n",
    "lnwriter = csv.writer(f)\n",
    "\n",
    "print(\"Instructions:\")\n",
    "print(\"- Move your head slightly or blink naturally\")\n",
    "print(\"- Stay still for too long = not live\")\n",
    "print(\"- Green box = Live person, Red = Static/Fake\")\n",
    "print(\"- Press 'q' to quit\")\n",
    "\n",
    "frame_count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10cfdc3-397d-47f8-8edd-2c0060a66fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marked for: Dewmini (Live person verified)\n",
      "Attendance marked for: Elon (Live person verified)\n",
      "Attendance session completed!\n",
      "Students marked present: ['Elon', 'Dewmini']\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame from camera\")\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Convert to grayscale for motion detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    \n",
    "    # Face recognition\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = np.ascontiguousarray(small_frame[:, :, ::-1].astype(np.uint8))\n",
    "    \n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "    \n",
    "    # Motion detection\n",
    "    motion_detected = False\n",
    "    if previous_frame is not None:\n",
    "        # Calculate frame difference\n",
    "        frame_delta = cv2.absdiff(previous_frame, gray)\n",
    "        thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        \n",
    "        # Calculate motion amount\n",
    "        motion_amount = cv2.countNonZero(thresh)\n",
    "        motion_detected = motion_amount > liveness_threshold\n",
    "        \n",
    "        # Show motion visualization (optional)\n",
    "        cv2.imshow(\"Motion Detection\", thresh)\n",
    "    \n",
    "    previous_frame = gray.copy()\n",
    "    \n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encoding, face_encoding)\n",
    "        face_distance = face_recognition.face_distance(known_face_encoding, face_encoding)\n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        \n",
    "        if matches[best_match_index]:\n",
    "            name = known_faces_names[best_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "            \n",
    "        face_names.append(name)\n",
    "        \n",
    "        # Initialize liveness tracking\n",
    "        if name not in liveness_verified and name != \"Unknown\":\n",
    "            liveness_verified[name] = {\n",
    "                \"motion_frames\": 0,\n",
    "                \"total_frames\": 0,\n",
    "                \"is_live\": False,\n",
    "                \"first_seen\": frame_count\n",
    "            }\n",
    "        \n",
    "        # Update liveness tracking\n",
    "        if name in liveness_verified:\n",
    "            liveness_verified[name][\"total_frames\"] += 1\n",
    "            if motion_detected:\n",
    "                liveness_verified[name][\"motion_frames\"] += 1\n",
    "            \n",
    "            # Calculate liveness percentage\n",
    "            motion_ratio = liveness_verified[name][\"motion_frames\"] / max(liveness_verified[name][\"total_frames\"], 1)\n",
    "            \n",
    "            # Verify liveness (need motion in at least 20% of frames and minimum frames)\n",
    "            if (liveness_verified[name][\"total_frames\"] >= motion_frames_required and \n",
    "                motion_ratio > 0.2):\n",
    "                liveness_verified[name][\"is_live\"] = True\n",
    "    \n",
    "    # Display faces with liveness status\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "        \n",
    "        # Determine status and color\n",
    "        if name == \"Unknown\":\n",
    "            color = (0, 0, 255)  # Red\n",
    "            status = \"Unknown\"\n",
    "            is_live = False\n",
    "        elif name in liveness_verified:\n",
    "            is_live = liveness_verified[name][\"is_live\"]\n",
    "            motion_ratio = liveness_verified[name][\"motion_frames\"] / max(liveness_verified[name][\"total_frames\"], 1)\n",
    "            frames_seen = liveness_verified[name][\"total_frames\"]\n",
    "            \n",
    "            if is_live:\n",
    "                color = (0, 255, 0)  # Green\n",
    "                status = \"LIVE\"\n",
    "            else:\n",
    "                color = (0, 165, 255)  # Orange\n",
    "                if frames_seen < motion_frames_required:\n",
    "                    status = f\"Analyzing... {frames_seen}/{motion_frames_required}\"\n",
    "                else:\n",
    "                    status = f\"Move more! {motion_ratio:.1%}\"\n",
    "        else:\n",
    "            color = (0, 0, 255)  # Red\n",
    "            status = \"Not recognized\"\n",
    "            is_live = False\n",
    "        \n",
    "        # Mark attendance only for live faces\n",
    "        if (name in students and is_live and \n",
    "            frame_count - liveness_verified[name][\"first_seen\"] > recognition_delay):\n",
    "            \n",
    "            students.remove(name)\n",
    "            print(f\"Attendance marked for: {name} (Live person verified)\")\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            lnwriter.writerow([name, current_time, \"Live\"])\n",
    "            f.flush()\n",
    "            \n",
    "            if len(students) == 0:\n",
    "                print(\"All students marked present! Closing camera...\")\n",
    "                break\n",
    "        \n",
    "        # Draw face rectangle and labels\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "        cv2.rectangle(frame, (left, bottom - 70), (right, bottom), color, cv2.FILLED)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 45), font, 0.6, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, status, (left + 6, bottom - 25), font, 0.4, (255, 255, 255), 1)\n",
    "        \n",
    "        # Show motion info for recognized faces\n",
    "        if name in liveness_verified:\n",
    "            motion_info = f\"Motion: {liveness_verified[name]['motion_frames']}/{liveness_verified[name]['total_frames']}\"\n",
    "            cv2.putText(frame, motion_info, (left + 6, bottom - 5), font, 0.3, (255, 255, 255), 1)\n",
    "    \n",
    "    # Display overall motion status\n",
    "    motion_text = \"MOTION DETECTED\" if motion_detected else \"NO MOTION\"\n",
    "    motion_color = (0, 255, 0) if motion_detected else (0, 0, 255)\n",
    "    cv2.putText(frame, motion_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, motion_color, 2)\n",
    "    \n",
    "    # Display remaining students\n",
    "    cv2.putText(frame, f\"Remaining: {len(students)}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Liveness Detection + Attendance\", frame)\n",
    "    \n",
    "    # Break conditions\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Auto-close if all students marked\n",
    "    if len(students) == 0:\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()\n",
    "\n",
    "print(\"Attendance session completed!\")\n",
    "print(\"Students marked present:\", [name for name in known_faces_names if name not in students])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4884eb-0f0c-4d69-8e8e-b8a08ed7d822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
